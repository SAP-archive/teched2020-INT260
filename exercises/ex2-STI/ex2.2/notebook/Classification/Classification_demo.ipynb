{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Demo\n",
    "\n",
    "In this notebook, we will see how to prepare the data for classification, upload the data, start training and do inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install pyjwt library if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyjwt\n",
    "!pip install pandas\n",
    "!pip install sklearn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import jwt\n",
    "import time\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training and test data\n",
    "\n",
    "We have a small dataset of service request tickets that is in the context of the travel industry. We will attempt to build a classifier which automatically classifies these tickets into their respective categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code block loads the data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/travel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's select the input and output mappings for training\n",
    "\n",
    "The mapping describes which columns in the upload file should be used as sample input and which ones are to be used as the classification output that the model should learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['Description']\n",
    "output_cols = ['Category']\n",
    "all_cols = input_cols + output_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data distribution\n",
    "\n",
    "After loading the data into dataframe, we check the distribution of classes (target variable).\n",
    "\n",
    "Usually the model works best if the dataset is balanced i.e. classes are equally distributed with little skewness, and each class has at least 1000 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(output_cols), ncols=1, figsize=(15, 10))\n",
    "for idx, output_col in enumerate(output_cols):\n",
    "    distribution = df[output_col].value_counts()\n",
    "    distribution.plot(kind='bar', rot=90, ax=axes[idx] if len(output_cols)!=1 else axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, test data split\n",
    "\n",
    "We split the loaded data into two sets\n",
    "1. Data we should upload and do the training\n",
    "2. Test data we use for testing the generated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df[all_cols], test_size = 0.01, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for output_col in output_cols:\n",
    "    print(output_col)\n",
    "    print(\"\\nTraining Data:\")\n",
    "    print(df_train[output_col].value_counts())\n",
    "    print(\"\\nTesting Data:\")\n",
    "    print(df_test[output_col].value_counts())\n",
    "    print(\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=len(output_cols), ncols=2, figsize=(20, 10))\n",
    "for idx, output_col in enumerate(output_cols):\n",
    "    df_train[output_col].value_counts().plot(kind='bar', rot=90, title='Training data', \n",
    "                                             ax=axes[idx][0] if len(output_cols)!=1 else axes[0] )\n",
    "    df_test[output_col].value_counts().plot(kind='bar', rot=90, title='Test Data',\n",
    "                                           ax=axes[idx][1] if len(output_cols)!=1 else axes[1])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STI REST Endpoints\n",
    "\n",
    "The STI service can be accessed and controlled through REST endpoint.\n",
    "Documentation can be found in the following link: https://help.sap.com/viewer/product/SERVICE_TICKET_INTELLIGENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription and Authentication\n",
    "\n",
    "Now we are ready to train a model using the Service Ticket Intelligence API. This requires a valid subscription to the STI API.\n",
    "\n",
    "Note: Update the values for `service url`, `uaa url`, `client id` and `client secret` in the config file `sti_config.ini`. This config file is placed one directory above this notebook. These values will be available in `service_keys` of your STI instance in the cloud foundry cockpit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use functions from `sti_functions.py` to access STI's REST endpoints. Feel free to browse the source code of it to see what's happening under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import sti_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(sti_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STI_BASE_DIR = Path.cwd().parent\n",
    "config_file_path = STI_BASE_DIR / 'sti_config.ini'\n",
    "\n",
    "connection = sti_functions.get_connection_object(config_file=config_file_path)\n",
    "sti = sti_functions.STIFunctions(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List models\n",
    "\n",
    "Now lets do list model call using this python function to view all the models in this account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sti.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check if we need to delete any unused model\n",
    "Based on the model list above, ensure that the number of models does not exceed 20. Otherwise, we need to delete some unused model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sti.delete_model(\"8c99a13d405948de82e9ccdf4f9ada17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File upload\n",
    "\n",
    "This process will take a few minutes to complete depending on the file size. If file upload is successful, the response text will contain a model id - an UUID identifier which we can use as a reference to the uploaded training file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train_base64 = base64.b64encode(df_train.to_csv(index=False).encode('utf-8'))\n",
    "payload = {\n",
    "    \"scenario\":\n",
    "      {\n",
    "          \"desc\":\"Travel data for classification\",\n",
    "          \"type\":\"classification\",\n",
    "          \"language\":\"en\",\n",
    "          \"business_object\":\"ticket\"\n",
    "      },\n",
    "      \"mapping\":\n",
    "      {\n",
    "            \"input\": input_cols,\n",
    "            \"output\": output_cols\n",
    "      },\n",
    "      \"training\":\n",
    "      {\n",
    "            \"file\": \"{}\".format(df_train_base64.decode('utf-8'))\n",
    "      }\n",
    "}\n",
    "response = sti.file_upload(payload)\n",
    "payload = {}\n",
    "our_model_id = response.get('model_id')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model status is new now. Once we submit training the `model_status` will transition from `NEW` -> `PENDING_TRAINING` -> `IN_TRAINING` -> `READY`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training on uploaded file\n",
    "\n",
    "Take the model id from file upload response text and pass it when in starting the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# our_model_id = \"a33807253a204ba5a2f6192a45b727d6\"\n",
    "sti.start_model_training(model_id=our_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for training to succeed\n",
    "\n",
    "After starting the model training, do a get model status and check if model status is `READY`\n",
    "\n",
    "The model status transitions from `NEW` to `PENDING_TRAINING` once training is submitted and will further transition to `IN_TRAINING` and finally `READY` when training succeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# our_model_id = \"cc078a539d6a433a92f0ac0a2fb445d2\"\n",
    "status = sti.get_model_status(model_id=our_model_id)\n",
    "print(\"Model status: {}\".format(status.get('model_status')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for model status to be `READY` before proceeding to next step. This will take upto 10-20 mins from the training submission time. Repeatedly run the above cell to get the latest model status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model status is `READY` proceed to next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy\n",
    "\n",
    "The model accuracy, confusion matrics and other metrics (such as f1, precision etc.,) can be retrived once training is completed and status becomes ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# our_model_id = \"cc078a539d6a433a92f0ac0a2fb445d2\"\n",
    "status = sti.get_model_status(model_id=our_model_id)\n",
    "print(\"Model combined accuracy:\", status[\"combined_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# our_model_id = \"cc078a539d6a433a92f0ac0a2fb445d2\"\n",
    "accuracy = sti.get_model_accuracy(model_id=our_model_id)\n",
    "for idx, result in enumerate(accuracy[\"validation_results\"]):\n",
    "    print(\"\\nField:\", accuracy[\"validation_results\"][idx][\"field\"])\n",
    "    print(\"Model average f1 score:\", accuracy[\"validation_results\"][idx][\"average_f1_score\"])\n",
    "    print(\"Model average precision:\", accuracy[\"validation_results\"][idx][\"average_precision\"])\n",
    "    print(\"Model average recall:\", accuracy[\"validation_results\"][idx][\"average_recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the confusion matrix as well to visually see the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sti.plot_confusion_matrix(model_id=our_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate the model\n",
    "\n",
    "Once you are satisfied with the results, model needs to activated before inference can be run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sti.activate_model(model_id=our_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build inference payload and send request\n",
    "\n",
    "We will select a random example from our `df_test` dataframe which has not been sent for training and evaluate how the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "payload[\"business_object\"] = \"ticket\"\n",
    "payload[\"messages\"] = [{\"id\": 2001, \"contents\": []}]\n",
    "for input_col in input_cols:\n",
    "    payload[\"messages\"][0]['contents'].append({\"field\": input_col, \"value\": df_test.iloc[8][input_col]})\n",
    "    \n",
    "inference_response = sti.classify_text(payload)\n",
    "inference_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore around by giving different input from `df_test` or your own input and see how the model performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets evaluate the STI model performance ourselves\n",
    "\n",
    "We also can run inference against all the data from `df_test` and evaluate by ourselves how the sti model performs. We will results from STI against the original value of the `df_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"business_object\": \"ticket\",\n",
    "    \"messages\": []\n",
    "}\n",
    "for index, row in df_test.iterrows():\n",
    "    tmp = {'id': index, 'contents': []}\n",
    "    for input_col in input_cols:\n",
    "        tmp['contents'].append({\"field\": input_col, \"value\": row[input_col]})\n",
    "\n",
    "    payload['messages'].append(tmp)\n",
    "\n",
    "inference_response = sti.classify_text(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true_collection = []\n",
    "y_pred_collection = []\n",
    "for idx, output_col in enumerate(output_cols):\n",
    "    y_true = [row[output_col] for _, row in df_test.iterrows()]\n",
    "    y_pred = [classification['classification'][idx]['value'] for classification in inference_response['results']]\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "    y_true_collection.append(y_true)\n",
    "    y_pred_collection.append(y_pred)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_results = sti.get_model_accuracy(model_id=our_model_id)\n",
    "for idx, (y_true, y_pred) in enumerate(zip(y_true_collection, y_pred_collection)):\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    cnf_mtrx = confusion_matrix(y_true, y_pred)\n",
    "    sti_functions.plot(cnf_mtrx, \n",
    "                       classes=model_results[\"validation_results\"][idx][\"confusion_matrix\"][\"labels\"], \n",
    "                       title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using STI's pre-trained models\n",
    "\n",
    "Apart from building custom models with your own data, STI also provides pre-trained models for sentiment analysis and language detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Detection\n",
    "\n",
    "You can use this to detect the language of text.\n",
    "ISO Language codes of message content will be shown in response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"business_object\": \"ticket\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            'id': 2001,\n",
    "            'contents': [\n",
    "                {\n",
    "                    'field': input_cols[0],\n",
    "                    'value': \"I don't like your service\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'id': 2002,\n",
    "            'contents': [\n",
    "                {\n",
    "                    'field': input_cols[0],\n",
    "                    'value': 'Ich mag deinen Service nicht'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"options\": {\n",
    "        \"services\": {\n",
    "            \"detect_language\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "inference_response = sti.classify_text(payload)\n",
    "inference_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Provides sentiment score of the input content ranging from -1 to 1. Highly negative sentiment will have score of -1 and highly positive sentiment will have a score of +1. And 0 may denote a neutral phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"business_object\": \"ticket\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            'id': 2001,\n",
    "            'contents': [\n",
    "                {\n",
    "                    'field': input_cols[0],\n",
    "                    'value': \"I don't like your service\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'id': 2002,\n",
    "            'contents': [\n",
    "                {\n",
    "                    'field': input_cols[0],\n",
    "                    'value': 'Ich mag deinen Service nicht'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"options\": {\n",
    "        \"services\": {\n",
    "            \"detect_sentiment\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "inference_response = sti.classify_text(payload)\n",
    "inference_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple services in same request.\n",
    "\n",
    "You can request one inference request to do category classification and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"business_object\": \"ticket\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            'id': 2001,\n",
    "            'contents': [\n",
    "                {\n",
    "                    'field': input_cols[0],\n",
    "                    'value': \"I don't like your service\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"options\": {\n",
    "        \"services\": {\n",
    "            \"detect_category\": True,\n",
    "            \"detect_sentiment\": True,\n",
    "            \"detect_language\": True,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "inference_response = sti.classify_text(payload)\n",
    "inference_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deactivate model\n",
    "\n",
    "We can deactivate any active models here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sti.deactivate_model(model_id=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete model\n",
    "\n",
    "We can delete any unused models here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sti.delete_model(model_id=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
